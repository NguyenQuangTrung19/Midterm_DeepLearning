{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400a1f67",
   "metadata": {
    "papermill": {
     "duration": 0.007817,
     "end_time": "2025-03-22T20:03:32.273352",
     "exception": false,
     "start_time": "2025-03-22T20:03:32.265535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcd7ec7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:32.699249Z",
     "iopub.status.busy": "2025-03-23T13:03:32.698979Z",
     "iopub.status.idle": "2025-03-23T13:03:47.564393Z",
     "shell.execute_reply": "2025-03-23T13:03:47.563694Z",
     "shell.execute_reply.started": "2025-03-23T13:03:32.699228Z"
    },
    "papermill": {
     "duration": 19.877006,
     "end_time": "2025-03-22T20:03:52.157685",
     "exception": false,
     "start_time": "2025-03-22T20:03:32.280679",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import string\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc4f95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:47.565714Z",
     "iopub.status.busy": "2025-03-23T13:03:47.565273Z",
     "iopub.status.idle": "2025-03-23T13:03:47.649889Z",
     "shell.execute_reply": "2025-03-23T13:03:47.649095Z",
     "shell.execute_reply.started": "2025-03-23T13:03:47.565690Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.09301,
     "end_time": "2025-03-22T20:03:52.258749",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.165739",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc00b0b",
   "metadata": {
    "papermill": {
     "duration": 0.007142,
     "end_time": "2025-03-22T20:03:52.273822",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.266680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bec0b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:47.651729Z",
     "iopub.status.busy": "2025-03-23T13:03:47.651454Z",
     "iopub.status.idle": "2025-03-23T13:03:47.879281Z",
     "shell.execute_reply": "2025-03-23T13:03:47.878491Z",
     "shell.execute_reply.started": "2025-03-23T13:03:47.651705Z"
    },
    "papermill": {
     "duration": 0.220843,
     "end_time": "2025-03-22T20:03:52.501926",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.281083",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>món này là món gì</td>\n",
       "      <td>bánh bèo</td>\n",
       "      <td>recognition</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đây có phải là bánh bèo không</td>\n",
       "      <td>có</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>boolean</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>màu chủ đạo của bánh bèo là gì</td>\n",
       "      <td>trắng</td>\n",
       "      <td>color</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bánh bèo có màu gì</td>\n",
       "      <td>trắng</td>\n",
       "      <td>color</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bánh bèo có nước chấm không</td>\n",
       "      <td>có</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>boolean</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         question    answer question_type answer_type  \\\n",
       "0               món này là món gì  bánh bèo   recognition        text   \n",
       "1   đây có phải là bánh bèo không        có        yes/no     boolean   \n",
       "2  màu chủ đạo của bánh bèo là gì     trắng         color        text   \n",
       "3              bánh bèo có màu gì     trắng         color        text   \n",
       "4     bánh bèo có nước chấm không        có        yes/no     boolean   \n",
       "\n",
       "             image_path  \n",
       "0  train/Banh_Beo/1.jpg  \n",
       "1  train/Banh_Beo/1.jpg  \n",
       "2  train/Banh_Beo/1.jpg  \n",
       "3  train/Banh_Beo/1.jpg  \n",
       "4  train/Banh_Beo/1.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = '/kaggle/input/food-vqa-v2/VN20-500_v3'\n",
    "# ROOT = '/kaggle/input/hand-image-vqa'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(f'{ROOT}/annotations/train.csv')\n",
    "val_df = pd.read_csv(f'{ROOT}/annotations/validation.csv')\n",
    "test_df = pd.read_csv(f'{ROOT}/annotations/test.csv')\n",
    "\n",
    "\n",
    "data =  pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28062636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:47.881093Z",
     "iopub.status.busy": "2025-03-23T13:03:47.880771Z",
     "iopub.status.idle": "2025-03-23T13:03:47.886918Z",
     "shell.execute_reply": "2025-03-23T13:03:47.886142Z",
     "shell.execute_reply.started": "2025-03-23T13:03:47.881070Z"
    },
    "papermill": {
     "duration": 0.014792,
     "end_time": "2025-03-22T20:03:52.525331",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.510539",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 41613, Val samples: 5518, Test samples: 10530\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('?', '').replace(',', '').lower().split(' ')\n",
    "    return '_'.join(text)\n",
    "    \n",
    "classes = {\n",
    "    'bánh bèo': 'bánh_bèo',\n",
    "    'bánh căn': 'bánh_căn',\n",
    "    'bánh giò': 'bánh_giò',\n",
    "    'bánh mì': 'bánh_mì',\n",
    "    'bánh tráng nướng': 'bánh_tráng_nướng',\n",
    "    'bánh xèo': 'bánh_xèo',\n",
    "    'bắp xào': 'bắp_xào',\n",
    "    'bún bò': 'bún_bò',\n",
    "    'bún chả': 'bún_chả',\n",
    "    'bún đậu': 'bún_đậu',\n",
    "    'bún mắm': 'bún_mắm',\n",
    "    'bún thịt nướng': 'bún_thịt_nướng',\n",
    "    'cao lầu': 'cao_lầu',\n",
    "    'cháo lòng': 'cháo_lòng',\n",
    "    'cơm tấm': 'cơm_tấm',\n",
    "    'gỏi cuốn': 'gỏi_cuốn',\n",
    "    'hủ tiếu': 'hủ_tiếu',\n",
    "    'mì quảng': 'mì_quảng',\n",
    "    'phá lấu': 'phá_lấu',\n",
    "    'phở': 'phở',\n",
    "    'chủ đạo': 'chủ_đạo',\n",
    "    'nước chấm': 'nước_chấm',\n",
    "    'màu sắc': 'màu_sắc',\n",
    "    \n",
    "    }\n",
    "print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}, Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b58f17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:47.888056Z",
     "iopub.status.busy": "2025-03-23T13:03:47.887841Z",
     "iopub.status.idle": "2025-03-23T13:03:47.977930Z",
     "shell.execute_reply": "2025-03-23T13:03:47.977124Z",
     "shell.execute_reply.started": "2025-03-23T13:03:47.888037Z"
    },
    "papermill": {
     "duration": 0.083919,
     "end_time": "2025-03-22T20:03:52.616906",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.532987",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['answer'] = data.answer.apply(clean_text)\n",
    "train_df['answer'] = train_df.answer.apply(clean_text)\n",
    "test_df['answer'] = test_df.answer.apply(clean_text)\n",
    "val_df['answer'] = val_df.answer.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bbd992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:47.979170Z",
     "iopub.status.busy": "2025-03-23T13:03:47.978892Z",
     "iopub.status.idle": "2025-03-23T13:03:47.987442Z",
     "shell.execute_reply": "2025-03-23T13:03:47.986731Z",
     "shell.execute_reply.started": "2025-03-23T13:03:47.979142Z"
    },
    "papermill": {
     "duration": 0.017156,
     "end_time": "2025-03-22T20:03:52.641667",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.624511",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>món này là món gì</td>\n",
       "      <td>bánh_bèo</td>\n",
       "      <td>recognition</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đây có phải là bánh bèo không</td>\n",
       "      <td>có</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>boolean</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>màu chủ đạo của bánh bèo là gì</td>\n",
       "      <td>trắng</td>\n",
       "      <td>color</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bánh bèo có màu gì</td>\n",
       "      <td>trắng</td>\n",
       "      <td>color</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bánh bèo có nước chấm không</td>\n",
       "      <td>có</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>boolean</td>\n",
       "      <td>train/Banh_Beo/1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         question    answer question_type answer_type  \\\n",
       "0               món này là món gì  bánh_bèo   recognition        text   \n",
       "1   đây có phải là bánh bèo không        có        yes/no     boolean   \n",
       "2  màu chủ đạo của bánh bèo là gì     trắng         color        text   \n",
       "3              bánh bèo có màu gì     trắng         color        text   \n",
       "4     bánh bèo có nước chấm không        có        yes/no     boolean   \n",
       "\n",
       "             image_path  \n",
       "0  train/Banh_Beo/1.jpg  \n",
       "1  train/Banh_Beo/1.jpg  \n",
       "2  train/Banh_Beo/1.jpg  \n",
       "3  train/Banh_Beo/1.jpg  \n",
       "4  train/Banh_Beo/1.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f636cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:47.988855Z",
     "iopub.status.busy": "2025-03-23T13:03:47.988520Z",
     "iopub.status.idle": "2025-03-23T13:03:48.046404Z",
     "shell.execute_reply": "2025-03-23T13:03:48.045829Z",
     "shell.execute_reply.started": "2025-03-23T13:03:47.988800Z"
    },
    "papermill": {
     "duration": 0.056873,
     "end_time": "2025-03-22T20:03:52.705779",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.648906",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57661 entries, 0 to 57660\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   question       57661 non-null  object\n",
      " 1   answer         57661 non-null  object\n",
      " 2   question_type  57661 non-null  object\n",
      " 3   answer_type    57661 non-null  object\n",
      " 4   image_path     57661 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa8152d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:48.047387Z",
     "iopub.status.busy": "2025-03-23T13:03:48.047108Z",
     "iopub.status.idle": "2025-03-23T13:03:48.093446Z",
     "shell.execute_reply": "2025-03-23T13:03:48.092815Z",
     "shell.execute_reply.started": "2025-03-23T13:03:48.047361Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.055415,
     "end_time": "2025-03-22T20:03:52.768811",
     "exception": false,
     "start_time": "2025-03-22T20:03:52.713396",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57661</td>\n",
       "      <td>57661</td>\n",
       "      <td>57661</td>\n",
       "      <td>57661</td>\n",
       "      <td>57661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3135</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>màu sắc chính của món ăn là gì</td>\n",
       "      <td>có</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>text</td>\n",
       "      <td>train/Banh_Beo/10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2130</td>\n",
       "      <td>21860</td>\n",
       "      <td>23837</td>\n",
       "      <td>32797</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question answer question_type answer_type  \\\n",
       "count                            57661  57661         57661       57661   \n",
       "unique                            3135     27             3           2   \n",
       "top     màu sắc chính của món ăn là gì     có        yes/no        text   \n",
       "freq                              2130  21860         23837       32797   \n",
       "\n",
       "                   image_path  \n",
       "count                   57661  \n",
       "unique                   9720  \n",
       "top     train/Banh_Beo/10.jpg  \n",
       "freq                       14  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa472cf",
   "metadata": {
    "papermill": {
     "duration": 0.025574,
     "end_time": "2025-03-22T20:04:01.567513",
     "exception": false,
     "start_time": "2025-03-22T20:04:01.541939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcf4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:48.096299Z",
     "iopub.status.busy": "2025-03-23T13:03:48.096068Z",
     "iopub.status.idle": "2025-03-23T13:03:48.101312Z",
     "shell.execute_reply": "2025-03-23T13:03:48.100491Z",
     "shell.execute_reply.started": "2025-03-23T13:03:48.096280Z"
    },
    "papermill": {
     "duration": 0.033558,
     "end_time": "2025-03-22T20:04:01.626637",
     "exception": false,
     "start_time": "2025-03-22T20:04:01.593079",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57661, 57661)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = data.question\n",
    "answers = data.answer\n",
    "\n",
    "len(questions), len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f634c96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:48.102929Z",
     "iopub.status.busy": "2025-03-23T13:03:48.102632Z",
     "iopub.status.idle": "2025-03-23T13:03:48.120072Z",
     "shell.execute_reply": "2025-03-23T13:03:48.119298Z",
     "shell.execute_reply.started": "2025-03-23T13:03:48.102900Z"
    },
    "papermill": {
     "duration": 0.032477,
     "end_time": "2025-03-22T20:04:01.683934",
     "exception": false,
     "start_time": "2025-03-22T20:04:01.651457",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, texts, pad_token='<pad>', unk_token='<unk>', pad_idx=0, unk_idx=1):\n",
    "        self.PAD_TOKEN = pad_token\n",
    "        self.UNK_TOKEN = unk_token\n",
    "        self.PAD_IDX = pad_idx\n",
    "        self.UNK_IDX = unk_idx\n",
    "        \n",
    "        self.vocab = self._build_vocab(texts)\n",
    "        self.vocab2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.size = len(self.vocab)\n",
    "\n",
    "    def word2idx(self, vocab):\n",
    "        if vocab in self.vocab2idx:\n",
    "            return self.vocab2idx[vocab]\n",
    "        else:\n",
    "            return self.vocab2idx[self.UNK_TOKEN]\n",
    "\n",
    "    def idx2word(self, idx):\n",
    "        return self.vocab[idx]\n",
    "\n",
    "    def _build_vocab(self, texts, min_freq=5):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            tokens = word_tokenize(text.lower())\n",
    "            counter.update(tokens)\n",
    "    \n",
    "        vocab = [self.PAD_TOKEN, self.UNK_TOKEN]  \n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq: \n",
    "                vocab.append(word)\n",
    "                \n",
    "        return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378706b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:48.121119Z",
     "iopub.status.busy": "2025-03-23T13:03:48.120916Z",
     "iopub.status.idle": "2025-03-23T13:03:48.143166Z",
     "shell.execute_reply": "2025-03-23T13:03:48.142583Z",
     "shell.execute_reply.started": "2025-03-23T13:03:48.121091Z"
    },
    "papermill": {
     "duration": 0.032681,
     "end_time": "2025-03-22T20:04:01.740571",
     "exception": false,
     "start_time": "2025-03-22T20:04:01.707890",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(self, data, q_vocab, a_vocab, transform=None, max_len=30, image_folder=f'{ROOT}/images'):\n",
    "        self.data = data\n",
    "        self.question_vocab = q_vocab\n",
    "        self.answer_vocab = a_vocab\n",
    "        self.transform = transform \n",
    "        \n",
    "        self.image_folder = image_folder\n",
    "        self.MAX_QUESTION_LEN = data.question.apply(lambda x: len(x.split(' '))).max()\n",
    "        self.MAX_ANSWER_LEN = data.answer.apply(lambda x: len(x.split(' '))).max()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        image_id = row['image_path']\n",
    "\n",
    "        question_tokens = word_tokenize(question)\n",
    "        question_indices = [self.question_vocab.word2idx(token) for token in question_tokens]\n",
    "        question_indices = question_indices[:self.MAX_QUESTION_LEN]  # Cắt nếu quá dài\n",
    "        question_indices += [self.question_vocab.PAD_IDX] * (self.MAX_QUESTION_LEN - len(question_indices))  # Padding nếu quá ngắn\n",
    "\n",
    "        answer_idx = self.answer_vocab.word2idx(answer)\n",
    "\n",
    "        image_path = os.path.join(self.image_folder, image_id)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return torch.tensor(question_indices, dtype=torch.long), image, torch.tensor(answer_idx, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9a33e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:48.144144Z",
     "iopub.status.busy": "2025-03-23T13:03:48.143889Z",
     "iopub.status.idle": "2025-03-23T13:03:55.370718Z",
     "shell.execute_reply": "2025-03-23T13:03:55.369859Z",
     "shell.execute_reply.started": "2025-03-23T13:03:48.144118Z"
    },
    "papermill": {
     "duration": 7.409787,
     "end_time": "2025-03-22T20:04:09.174654",
     "exception": false,
     "start_time": "2025-03-22T20:04:01.764867",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vocab = Vocab(questions)\n",
    "answer_vocab = Vocab(answers)\n",
    "\n",
    "answer_vocab.vocab\n",
    "question_vocab.vocab\n",
    "len(question_vocab.vocab), len(answer_vocab.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a2d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.414493Z",
     "iopub.status.busy": "2025-03-23T13:03:55.414129Z",
     "iopub.status.idle": "2025-03-23T13:03:55.434547Z",
     "shell.execute_reply": "2025-03-23T13:03:55.434006Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.414376Z"
    },
    "papermill": {
     "duration": 0.029881,
     "end_time": "2025-03-22T20:04:09.392562",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.362681",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch, PAD_IDX=0):\n",
    "    questions, images, answers = zip(*batch) \n",
    "    \n",
    "    questions = [torch.tensor(q) for q in questions]\n",
    "    padded_questions = pad_sequence(questions, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "    answer = [torch.tensor(a) for a in answers]\n",
    "    \n",
    "    images = torch.stack(images)  \n",
    "    answer = torch.tensor(answer) \n",
    "\n",
    "    return padded_questions, images, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d489e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.435627Z",
     "iopub.status.busy": "2025-03-23T13:03:55.435347Z",
     "iopub.status.idle": "2025-03-23T13:03:55.454224Z",
     "shell.execute_reply": "2025-03-23T13:03:55.453643Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.435599Z"
    },
    "papermill": {
     "duration": 0.029052,
     "end_time": "2025-03-22T20:04:09.447943",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.418891",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize lớn hơn trước khi crop\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "179cf541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.455285Z",
     "iopub.status.busy": "2025-03-23T13:03:55.455003Z",
     "iopub.status.idle": "2025-03-23T13:03:55.536304Z",
     "shell.execute_reply": "2025-03-23T13:03:55.535744Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.455259Z"
    },
    "papermill": {
     "duration": 0.09752,
     "end_time": "2025-03-22T20:04:09.569156",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.471636",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41613"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = VQADataset(train_df, question_vocab, answer_vocab, transform=transform)\n",
    "val_dataset = VQADataset(val_df, question_vocab, answer_vocab, transform=transform)\n",
    "test_dataset = VQADataset(test_df, question_vocab, answer_vocab, transform=transform)\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22d1696a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.537089Z",
     "iopub.status.busy": "2025-03-23T13:03:55.536925Z",
     "iopub.status.idle": "2025-03-23T13:03:55.541228Z",
     "shell.execute_reply": "2025-03-23T13:03:55.540396Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.537075Z"
    },
    "papermill": {
     "duration": 0.032375,
     "end_time": "2025-03-22T20:04:09.627574",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.595199",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, drop_last=True, num_workers=10)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True, num_workers=10)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6782d359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.542371Z",
     "iopub.status.busy": "2025-03-23T13:03:55.542117Z",
     "iopub.status.idle": "2025-03-23T13:03:55.559588Z",
     "shell.execute_reply": "2025-03-23T13:03:55.558868Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.542344Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.038123,
     "end_time": "2025-03-22T20:04:09.691811",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.653688",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_val_loss = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        # Check if validation loss is nan\n",
    "        if np.isnan(val_loss):\n",
    "            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n",
    "            return\n",
    "\n",
    "        if self.best_val_loss is None:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss < self.best_val_loss - self.delta:\n",
    "            # Significant improvement detected\n",
    "            self.best_val_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0  # Reset counter since improvement occurred\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0887193c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.560764Z",
     "iopub.status.busy": "2025-03-23T13:03:55.560475Z",
     "iopub.status.idle": "2025-03-23T13:03:55.583469Z",
     "shell.execute_reply": "2025-03-23T13:03:55.582891Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.560736Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.035553,
     "end_time": "2025-03-22T20:04:09.753950",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.718397",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_history(history, train_loss, val_loss, train_acc, val_acc):\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "def log_training(epoch, epochs, train_loss, train_acc, val_loss, val_acc, early_stopping, start_time):\n",
    "    end_time = time.time()\n",
    "    print(f\"{'-' * 50}\")\n",
    "    print(f\"Epoch: {epoch + 1}/{epochs}:\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"\\tVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"\\tEarly Stopping Counter: {early_stopping.counter}, Time: {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2683e1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.584380Z",
     "iopub.status.busy": "2025-03-23T13:03:55.584173Z",
     "iopub.status.idle": "2025-03-23T13:03:55.601051Z",
     "shell.execute_reply": "2025-03-23T13:03:55.600462Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.584362Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.034636,
     "end_time": "2025-03-22T20:04:09.815648",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.781012",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for questions, images, answers in val_loader:\n",
    "            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n",
    "\n",
    "            output = model(questions, images)  # [batch, num_answer]\n",
    "\n",
    "            loss = criterion(output, answers)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Tính accuracy\n",
    "            predicted = torch.argmax(output, dim=-1)  # [batch]\n",
    "            correct_val += (predicted == answers).sum().item()\n",
    "            total_val += answers.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct_val / total_val\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32b1e43d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.602029Z",
     "iopub.status.busy": "2025-03-23T13:03:55.601772Z",
     "iopub.status.idle": "2025-03-23T13:03:55.626245Z",
     "shell.execute_reply": "2025-03-23T13:03:55.625697Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.602011Z"
    },
    "papermill": {
     "duration": 0.036109,
     "end_time": "2025-03-22T20:04:09.877812",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.841703",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, early_stopping):\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for questions, images, answers in train_loader:\n",
    "            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(questions, images)  # [batch_size, num_answer]\n",
    "            \n",
    "\n",
    "            loss = criterion(output, answers)  # [batch, num_answer] và [batch]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Tính accuracy\n",
    "            predicted = torch.argmax(output, dim=-1)  # [batch]\n",
    "            correct_train += (predicted == answers).sum().item()\n",
    "            total_train += answers.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        update_history(history, train_loss, val_loss, train_acc, val_acc)\n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "        log_training(epoch, epochs, train_loss, train_acc, val_loss, val_acc, early_stopping, start_time)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c78d7eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.627101Z",
     "iopub.status.busy": "2025-03-23T13:03:55.626923Z",
     "iopub.status.idle": "2025-03-23T13:03:55.649039Z",
     "shell.execute_reply": "2025-03-23T13:03:55.648473Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.627086Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.036384,
     "end_time": "2025-03-22T20:04:09.940973",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.904589",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for questions, images, answers in test_loader:\n",
    "            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n",
    "\n",
    "            output = model(questions, images)  # [batch, num_answer]\n",
    "\n",
    "            # Tính loss\n",
    "            loss = criterion(output, answers)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Lấy nhãn dự đoán\n",
    "            predicted = torch.argmax(output, dim=-1)  # [batch]\n",
    "            predictions.append(predicted.cpu().numpy())  # Chuyển sang numpy để phân tích\n",
    "\n",
    "            # Tính số lượng đúng\n",
    "            correct += (predicted == answers).sum().item()\n",
    "            total += answers.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = correct / total\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    return test_loss, test_acc, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b6c8f",
   "metadata": {
    "papermill": {
     "duration": 0.025694,
     "end_time": "2025-03-22T20:04:09.993760",
     "exception": false,
     "start_time": "2025-03-22T20:04:09.968066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f02d130a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.650103Z",
     "iopub.status.busy": "2025-03-23T13:03:55.649899Z",
     "iopub.status.idle": "2025-03-23T13:03:55.674860Z",
     "shell.execute_reply": "2025-03-23T13:03:55.674049Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.650075Z"
    },
    "papermill": {
     "duration": 0.039481,
     "end_time": "2025-03-22T20:04:10.058938",
     "exception": false,
     "start_time": "2025-03-22T20:04:10.019457",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, input_channels=3, feature_dim=256):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(512, feature_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        return self.dropout(self.fc(features))\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=512, num_layers=2):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 256)\n",
    "        self.batchnorm = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        hidden = lstm_out[:, -1, :]\n",
    "        hidden = self.fc(hidden)\n",
    "        return self.dropout(self.batchnorm(hidden))\n",
    "\n",
    "class VQAClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super(VQAClassifier, self).__init__()\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder(vocab_size)\n",
    "        self.fc_fusion = nn.Linear(256 * 2, 256)\n",
    "        self.activation_fusion = nn.ReLU()\n",
    "        self.batchnorm_fusion = nn.BatchNorm1d(256)\n",
    "        self.dropout_fusion = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, question, image):\n",
    "        img_features = self.image_encoder(image)\n",
    "        text_features = self.text_encoder(question)\n",
    "        fused = torch.cat((img_features, text_features), dim=1)\n",
    "        fused = self.fc_fusion(fused)\n",
    "        fused = self.activation_fusion(fused)\n",
    "        fused = self.batchnorm_fusion(fused)\n",
    "        fused = self.dropout_fusion(fused)\n",
    "        return self.classifier(fused)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488f39d",
   "metadata": {
    "papermill": {
     "duration": 0.026273,
     "end_time": "2025-03-22T20:04:10.111950",
     "exception": false,
     "start_time": "2025-03-22T20:04:10.085677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2a18cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:55.676055Z",
     "iopub.status.busy": "2025-03-23T13:03:55.675810Z",
     "iopub.status.idle": "2025-03-23T13:03:56.294147Z",
     "shell.execute_reply": "2025-03-23T13:03:56.293349Z",
     "shell.execute_reply.started": "2025-03-23T13:03:55.676014Z"
    },
    "papermill": {
     "duration": 1.152332,
     "end_time": "2025-03-22T20:04:11.290086",
     "exception": false,
     "start_time": "2025-03-22T20:04:10.137754",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = VQAClassifier(\n",
    "    vocab_size=question_vocab.size,\n",
    "    num_classes=answer_vocab.size\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970c9ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:56.297095Z",
     "iopub.status.busy": "2025-03-23T13:03:56.296875Z",
     "iopub.status.idle": "2025-03-23T13:03:56.301854Z",
     "shell.execute_reply": "2025-03-23T13:03:56.300976Z",
     "shell.execute_reply.started": "2025-03-23T13:03:56.297077Z"
    },
    "papermill": {
     "duration": 0.032749,
     "end_time": "2025-03-22T20:04:11.348665",
     "exception": false,
     "start_time": "2025-03-22T20:04:11.315916",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=question_vocab.PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=8, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637b970",
   "metadata": {
    "papermill": {
     "duration": 0.024144,
     "end_time": "2025-03-22T20:04:11.398347",
     "exception": false,
     "start_time": "2025-03-22T20:04:11.374203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d5984",
   "metadata": {
    "papermill": {
     "duration": 0.027726,
     "end_time": "2025-03-22T20:04:11.456632",
     "exception": false,
     "start_time": "2025-03-22T20:04:11.428906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582b242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:03:56.303063Z",
     "iopub.status.busy": "2025-03-23T13:03:56.302774Z"
    },
    "papermill": {
     "duration": 2241.842097,
     "end_time": "2025-03-22T20:41:33.325965",
     "exception": false,
     "start_time": "2025-03-22T20:04:11.483868",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "history = train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc6dea",
   "metadata": {
    "papermill": {
     "duration": 0.025898,
     "end_time": "2025-03-22T20:41:33.377944",
     "exception": false,
     "start_time": "2025-03-22T20:41:33.352046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c08c6b",
   "metadata": {
    "papermill": {
     "duration": 24.340582,
     "end_time": "2025-03-22T20:41:57.745680",
     "exception": false,
     "start_time": "2025-03-22T20:41:33.405098",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(early_stopping.path))\n",
    "test_loss, test_acc, predictions = test(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3ef1f",
   "metadata": {
    "papermill": {
     "duration": 0.033976,
     "end_time": "2025-03-22T20:41:57.806510",
     "exception": false,
     "start_time": "2025-03-22T20:41:57.772534",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    # Vẽ Train Loss và Eval Loss\n",
    "    axes[0].plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    axes[0].plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Training and Validation Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Vẽ Train Accuracy và Eval Accuracy\n",
    "    axes[1].plot(epochs, history[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    axes[1].plot(epochs, history[\"val_acc\"], label=\"Val Accuracy\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].set_title(\"Training and Validation Accuracy\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ede65",
   "metadata": {
    "papermill": {
     "duration": 0.677266,
     "end_time": "2025-03-22T20:41:58.509069",
     "exception": false,
     "start_time": "2025-03-22T20:41:57.831803",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_training_history(history, title='Vqa early fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26597cc",
   "metadata": {
    "papermill": {
     "duration": 1.470318,
     "end_time": "2025-03-22T20:42:00.009676",
     "exception": false,
     "start_time": "2025-03-22T20:41:58.539358",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in [random.randint(0, len(test_dataset) - 1) for _ in range(20)]:\n",
    "    model.eval()\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model.module.eval()\n",
    "    question, image, answer = test_dataset[i]\n",
    "    \n",
    "    # Đưa dữ liệu lên GPU nếu cần\n",
    "    question, image = question.to(device), image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(question.unsqueeze(0), image.unsqueeze(0))  # (1, num_answer)\n",
    "        predicted_idx = torch.argmax(output, dim=1).item()  # Lấy chỉ mục của câu trả lời dự đoán\n",
    "\n",
    "    # Lấy câu hỏi và câu trả lời thực tế từ dataset\n",
    "    question_text = test_dataset.data.iloc[i]['question']\n",
    "    answer_text = test_dataset.data.iloc[i]['answer']\n",
    "\n",
    "    # Chuyển index thành câu trả lời\n",
    "    predicted_answer = test_dataset.answer_vocab.idx2word(predicted_idx)\n",
    "\n",
    "    # Hiển thị ảnh\n",
    "    image_np = image.cpu().permute(1, 2, 0).numpy()  # Chuyển tensor thành numpy array\n",
    "    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())  # Chuẩn hóa về [0,1]\n",
    "\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"❓ Question: {question_text}\")\n",
    "    print(f\"✅ GT Answer: {answer_text}\")\n",
    "    print(f\"🔮 Predicted Answer: {predicted_answer}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6945560,
     "sourceId": 11135839,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2314.965699,
   "end_time": "2025-03-22T20:42:03.537604",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-22T20:03:28.571905",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
