{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11133576,"sourceType":"datasetVersion","datasetId":6943938}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2314.965699,"end_time":"2025-03-22T20:42:03.537604","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-22T20:03:28.571905","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"400a1f67","cell_type":"markdown","source":"# Import libraries","metadata":{"papermill":{"duration":0.007817,"end_time":"2025-03-22T20:03:32.273352","exception":false,"start_time":"2025-03-22T20:03:32.265535","status":"completed"},"tags":[]}},{"id":"2bcd7ec7","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\nimport timm\n\nfrom sklearn.model_selection import train_test_split\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud\n\nimport os\nimport time\nimport warnings\nimport random\nimport string\nfrom collections import Counter\nfrom PIL import Image\n\n\nsns.set_context(\"paper\")\nsns.set_style(\"whitegrid\")\n\nwarnings.filterwarnings('ignore')\nnltk.download('punkt')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-23T13:01:34.972034Z","iopub.execute_input":"2025-03-23T13:01:34.972338Z","iopub.status.idle":"2025-03-23T13:01:39.116630Z","shell.execute_reply.started":"2025-03-23T13:01:34.972312Z","shell.execute_reply":"2025-03-23T13:01:39.113662Z"},"papermill":{"duration":19.877006,"end_time":"2025-03-22T20:03:52.157685","exception":false,"start_time":"2025-03-22T20:03:32.280679","status":"completed"},"tags":[],"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-21fe846a796e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m from torch import (\n\u001b[0m\u001b[1;32m   2476\u001b[0m     \u001b[0mexport\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPassResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPassManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from torch.utils._pytree import (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_drawer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnet_min_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparam_fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/graph_drawer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_format_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_qualified_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator_schemas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_prop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/shape_prop.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_fake_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sparse_any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TensorMetadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ShapeProp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from torch._subclasses.fake_tensor import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mDynamicOutputShapeException\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFakeTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFakeTensorMode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCapturedTraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_fake_tensor_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_CacheKeyState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PySymInputStub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SymIntOutputStub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/_fake_tensor_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msym_node\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_sym_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPySymType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backport_slots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass_slots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"id":"cfc4f95a","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.117270Z","iopub.status.idle":"2025-03-23T13:01:39.117527Z","shell.execute_reply":"2025-03-23T13:01:39.117422Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.09301,"end_time":"2025-03-22T20:03:52.258749","exception":false,"start_time":"2025-03-22T20:03:52.165739","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7dc00b0b","cell_type":"markdown","source":"# Data preparing","metadata":{"papermill":{"duration":0.007142,"end_time":"2025-03-22T20:03:52.273822","exception":false,"start_time":"2025-03-22T20:03:52.266680","status":"completed"},"tags":[]}},{"id":"3bec0b50","cell_type":"code","source":"ROOT = '/kaggle/input/food-vqa-v2/VN20-500_v3'\n\n\ntrain_df = pd.read_csv(f'{ROOT}/annotations/train.csv')\nval_df = pd.read_csv(f'{ROOT}/annotations/validation.csv')\ntest_df = pd.read_csv(f'{ROOT}/annotations/test.csv')\n\n\ndata =  pd.concat([train_df, val_df, test_df], ignore_index=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.118241Z","iopub.status.idle":"2025-03-23T13:01:39.118662Z","shell.execute_reply":"2025-03-23T13:01:39.118480Z"},"papermill":{"duration":0.220843,"end_time":"2025-03-22T20:03:52.501926","exception":false,"start_time":"2025-03-22T20:03:52.281083","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"28062636","cell_type":"code","source":"def clean_text(text):\n    text = text.replace('?', '').replace(',', '').lower().split(' ')\n    return '_'.join(text)\n    \nclasses = {\n    'bánh bèo': 'bánh_bèo',\n    'bánh căn': 'bánh_căn',\n    'bánh giò': 'bánh_giò',\n    'bánh mì': 'bánh_mì',\n    'bánh tráng nướng': 'bánh_tráng_nướng',\n    'bánh xèo': 'bánh_xèo',\n    'bắp xào': 'bắp_xào',\n    'bún bò': 'bún_bò',\n    'bún chả': 'bún_chả',\n    'bún đậu': 'bún_đậu',\n    'bún mắm': 'bún_mắm',\n    'bún thịt nướng': 'bún_thịt_nướng',\n    'cao lầu': 'cao_lầu',\n    'cháo lòng': 'cháo_lòng',\n    'cơm tấm': 'cơm_tấm',\n    'gỏi cuốn': 'gỏi_cuốn',\n    'hủ tiếu': 'hủ_tiếu',\n    'mì quảng': 'mì_quảng',\n    'phá lấu': 'phá_lấu',\n    'phở': 'phở',\n    'chủ đạo': 'chủ_đạo',\n    'nước chấm': 'nước_chấm',\n    'màu sắc': 'màu_sắc',\n    \n    }\nprint(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}, Test samples: {len(test_df)}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.119514Z","iopub.status.idle":"2025-03-23T13:01:39.119798Z","shell.execute_reply":"2025-03-23T13:01:39.119686Z"},"papermill":{"duration":0.014792,"end_time":"2025-03-22T20:03:52.525331","exception":false,"start_time":"2025-03-22T20:03:52.510539","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f2b58f17","cell_type":"code","source":"data['answer'] = data.answer.apply(clean_text)\ntrain_df['answer'] = train_df.answer.apply(clean_text)\ntest_df['answer'] = test_df.answer.apply(clean_text)\nval_df['answer'] = val_df.answer.apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.120556Z","iopub.status.idle":"2025-03-23T13:01:39.120820Z","shell.execute_reply":"2025-03-23T13:01:39.120714Z"},"papermill":{"duration":0.083919,"end_time":"2025-03-22T20:03:52.616906","exception":false,"start_time":"2025-03-22T20:03:52.532987","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"72bbd992","cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.121346Z","iopub.status.idle":"2025-03-23T13:01:39.121582Z","shell.execute_reply":"2025-03-23T13:01:39.121486Z"},"papermill":{"duration":0.017156,"end_time":"2025-03-22T20:03:52.641667","exception":false,"start_time":"2025-03-22T20:03:52.624511","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7f636cf4","cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.122225Z","iopub.status.idle":"2025-03-23T13:01:39.122461Z","shell.execute_reply":"2025-03-23T13:01:39.122365Z"},"papermill":{"duration":0.056873,"end_time":"2025-03-22T20:03:52.705779","exception":false,"start_time":"2025-03-22T20:03:52.648906","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2aa472cf","cell_type":"markdown","source":"# Data preprocessing","metadata":{"papermill":{"duration":0.025574,"end_time":"2025-03-22T20:04:01.567513","exception":false,"start_time":"2025-03-22T20:04:01.541939","status":"completed"},"tags":[]}},{"id":"0fdcf4fc","cell_type":"code","source":"questions = data.question\nanswers = data.answer\n\n\nlen(questions), len(answers)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.123025Z","iopub.status.idle":"2025-03-23T13:01:39.123376Z","shell.execute_reply":"2025-03-23T13:01:39.123251Z"},"papermill":{"duration":0.033558,"end_time":"2025-03-22T20:04:01.626637","exception":false,"start_time":"2025-03-22T20:04:01.593079","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4f634c96","cell_type":"code","source":"class Vocab():\n    def __init__(self, texts, pad_token='<pad>', unk_token='<unk>', pad_idx=0, unk_idx=1):\n        self.PAD_TOKEN = pad_token\n        self.UNK_TOKEN = unk_token\n        self.PAD_IDX = pad_idx\n        self.UNK_IDX = unk_idx\n        \n        self.vocab = self._build_vocab(texts)\n        self.vocab2idx = {word: idx for idx, word in enumerate(self.vocab)}\n        self.size = len(self.vocab)\n\n    def word2idx(self, vocab):\n        if vocab in self.vocab2idx:\n            return self.vocab2idx[vocab]\n        else:\n            return self.vocab2idx[self.UNK_TOKEN]\n\n    def idx2word(self, idx):\n        return self.vocab[idx]\n\n    def _build_vocab(self, texts, min_freq=5):\n        counter = Counter()\n        for text in texts:\n            tokens = word_tokenize(text.lower())\n            counter.update(tokens)\n    \n        vocab = [self.PAD_TOKEN, self.UNK_TOKEN]  \n        for word, freq in counter.items():\n            if freq >= min_freq: \n                vocab.append(word)\n                \n        return vocab","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.124074Z","iopub.status.idle":"2025-03-23T13:01:39.124433Z","shell.execute_reply":"2025-03-23T13:01:39.124314Z"},"papermill":{"duration":0.032477,"end_time":"2025-03-22T20:04:01.683934","exception":false,"start_time":"2025-03-22T20:04:01.651457","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4378706b","cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, data, q_vocab, a_vocab, transform=None, max_len=30, image_folder=f'{ROOT}/images'):\n        self.data = data\n        self.question_vocab = q_vocab\n        self.answer_vocab = a_vocab\n        # self.question_vocab = Vocab(self.data.question)\n        # self.answer_vocab = Vocab(self.data.answer)\n        self.transform = transform \n        \n        self.image_folder = image_folder\n        self.MAX_QUESTION_LEN = data.question.apply(lambda x: len(x.split(' '))).max()\n        self.MAX_ANSWER_LEN = data.answer.apply(lambda x: len(x.split(' '))).max()\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        \n        question = row['question']\n        answer = row['answer']\n        image_id = row['image_path']\n\n        question_tokens = word_tokenize(question)\n        question_indices = [self.question_vocab.word2idx(token) for token in question_tokens]\n        question_indices = question_indices[:self.MAX_QUESTION_LEN]  # Cắt nếu quá dài\n        question_indices += [self.question_vocab.PAD_IDX] * (self.MAX_QUESTION_LEN - len(question_indices))  # Padding nếu quá ngắn\n\n        # answer_token = word_tokenize(answer)  \n        answer_idx = self.answer_vocab.word2idx(answer)\n\n        image_path = os.path.join(self.image_folder, image_id)\n        image = Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n\n        return torch.tensor(question_indices, dtype=torch.long), image, torch.tensor(answer_idx, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.125308Z","iopub.status.idle":"2025-03-23T13:01:39.125627Z","shell.execute_reply":"2025-03-23T13:01:39.125494Z"},"papermill":{"duration":0.032681,"end_time":"2025-03-22T20:04:01.740571","exception":false,"start_time":"2025-03-22T20:04:01.707890","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"fa9a33e5","cell_type":"code","source":"question_vocab = Vocab(questions)\nanswer_vocab = Vocab(answers)\n\nanswer_vocab.vocab\nquestion_vocab.vocab\nlen(question_vocab.vocab), len(answer_vocab.vocab)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.126697Z","iopub.status.idle":"2025-03-23T13:01:39.126989Z","shell.execute_reply":"2025-03-23T13:01:39.126874Z"},"papermill":{"duration":7.409787,"end_time":"2025-03-22T20:04:09.174654","exception":false,"start_time":"2025-03-22T20:04:01.764867","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"cb5a2d77","cell_type":"code","source":"def collate_fn(batch, PAD_IDX=0):\n    questions, images, answers = zip(*batch) \n    \n    questions = [torch.tensor(q) for q in questions]\n    padded_questions = pad_sequence(questions, batch_first=True, padding_value=PAD_IDX)\n\n    answer = [torch.tensor(a) for a in answers]\n    \n    images = torch.stack(images)  \n    answer = torch.tensor(answer) \n\n    return padded_questions, images, answer","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.128955Z","iopub.status.idle":"2025-03-23T13:01:39.129260Z","shell.execute_reply":"2025-03-23T13:01:39.129151Z"},"papermill":{"duration":0.029881,"end_time":"2025-03-22T20:04:09.392562","exception":false,"start_time":"2025-03-22T20:04:09.362681","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"565d489e","cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.130000Z","iopub.status.idle":"2025-03-23T13:01:39.130317Z","shell.execute_reply":"2025-03-23T13:01:39.130180Z"},"papermill":{"duration":0.029052,"end_time":"2025-03-22T20:04:09.447943","exception":false,"start_time":"2025-03-22T20:04:09.418891","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"179cf541","cell_type":"code","source":"train_dataset = VQADataset(train_df, question_vocab, answer_vocab, transform=transform)\nval_dataset = VQADataset(val_df, question_vocab, answer_vocab, transform=transform)\ntest_dataset = VQADataset(test_df, question_vocab, answer_vocab, transform=transform)\n\nlen(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.130960Z","iopub.status.idle":"2025-03-23T13:01:39.131294Z","shell.execute_reply":"2025-03-23T13:01:39.131183Z"},"papermill":{"duration":0.09752,"end_time":"2025-03-22T20:04:09.569156","exception":false,"start_time":"2025-03-22T20:04:09.471636","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"22d1696a","cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, drop_last=True, num_workers=10)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True, num_workers=10)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True, num_workers=10)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.131946Z","iopub.status.idle":"2025-03-23T13:01:39.132256Z","shell.execute_reply":"2025-03-23T13:01:39.132145Z"},"papermill":{"duration":0.032375,"end_time":"2025-03-22T20:04:09.627574","exception":false,"start_time":"2025-03-22T20:04:09.595199","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"6782d359","cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_val_loss = None\n        self.early_stop = False\n        self.val_loss_min = np.inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n        # Check if validation loss is nan\n        if np.isnan(val_loss):\n            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n            return\n\n        if self.best_val_loss is None:\n            self.best_val_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n        elif val_loss < self.best_val_loss - self.delta:\n            # Significant improvement detected\n            self.best_val_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0  # Reset counter since improvement occurred\n        else:\n            # No significant improvement\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decreases.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.132912Z","iopub.status.idle":"2025-03-23T13:01:39.133273Z","shell.execute_reply":"2025-03-23T13:01:39.133086Z"},"papermill":{"duration":0.038123,"end_time":"2025-03-22T20:04:09.691811","exception":false,"start_time":"2025-03-22T20:04:09.653688","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"0887193c","cell_type":"code","source":"def update_history(history, train_loss, val_loss, train_acc, val_acc):\n    history[\"train_loss\"].append(train_loss)\n    history[\"val_loss\"].append(val_loss)\n    history[\"train_acc\"].append(train_acc)\n    history[\"val_acc\"].append(val_acc)\n\ndef log_training(epoch, epochs, train_loss, train_acc, val_loss, val_acc, early_stopping, start_time):\n    end_time = time.time()\n    print(f\"{'-' * 50}\")\n    print(f\"Epoch: {epoch + 1}/{epochs}:\")\n    print(f\"\\tTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"\\tVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    print(f\"\\tEarly Stopping Counter: {early_stopping.counter}, Time: {end_time - start_time:.2f}s\")","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.134665Z","iopub.status.idle":"2025-03-23T13:01:39.135129Z","shell.execute_reply":"2025-03-23T13:01:39.134889Z"},"papermill":{"duration":0.035553,"end_time":"2025-03-22T20:04:09.753950","exception":false,"start_time":"2025-03-22T20:04:09.718397","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2683e1fd","cell_type":"code","source":"def validate(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n\n    with torch.no_grad():\n        for questions, images, answers in val_loader:\n            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n\n            output = model(questions, images)  # [batch, num_answer]\n\n            loss = criterion(output, answers)\n            val_loss += loss.item()\n\n            predicted = torch.argmax(output, dim=-1)  # [batch]\n            correct_val += (predicted == answers).sum().item()\n            total_val += answers.size(0)\n\n    val_loss /= len(val_loader)\n    val_acc = correct_val / total_val\n\n    return val_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.136339Z","iopub.status.idle":"2025-03-23T13:01:39.136716Z","shell.execute_reply":"2025-03-23T13:01:39.136552Z"},"papermill":{"duration":0.034636,"end_time":"2025-03-22T20:04:09.815648","exception":false,"start_time":"2025-03-22T20:04:09.781012","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"32b1e43d","cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, early_stopping):\n    history = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"train_acc\": [],\n        \"val_acc\": []\n    }\n\n    print('Start training...')\n    for epoch in range(epochs):\n        start_time = time.time()\n        \n        model.train()\n        train_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        for questions, images, answers in train_loader:\n            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n\n            optimizer.zero_grad()\n            output = model(questions, images)  # [batch_size, num_answer]\n            \n\n            loss = criterion(output, answers)  # [batch, num_answer] và [batch]\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n\n            # Tính accuracy\n            predicted = torch.argmax(output, dim=-1)  # [batch]\n            correct_train += (predicted == answers).sum().item()\n            total_train += answers.size(0)\n\n        train_loss /= len(train_loader)\n        train_acc = correct_train / total_train\n\n        # Validation\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n\n        update_history(history, train_loss, val_loss, train_acc, val_acc)\n        # scheduler.step(val_loss)\n\n        early_stopping(val_loss, model)\n        if early_stopping.early_stop:\n            print(\"Early stopping triggered\")\n            break\n    \n        log_training(epoch, epochs, train_loss, train_acc, val_loss, val_acc, early_stopping, start_time)\n\n    return history\n","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.137479Z","iopub.status.idle":"2025-03-23T13:01:39.137920Z","shell.execute_reply":"2025-03-23T13:01:39.137734Z"},"papermill":{"duration":0.036109,"end_time":"2025-03-22T20:04:09.877812","exception":false,"start_time":"2025-03-22T20:04:09.841703","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c78d7eb3","cell_type":"code","source":"def test(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n    predictions = []\n\n    with torch.no_grad():\n        for questions, images, answers in test_loader:\n            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n\n            output = model(questions, images)  # [batch, num_answer]\n\n            # Tính loss\n            loss = criterion(output, answers)\n            test_loss += loss.item()\n\n            # Lấy nhãn dự đoán\n            predicted = torch.argmax(output, dim=-1)  # [batch]\n            predictions.append(predicted.cpu().numpy())  # Chuyển sang numpy để phân tích\n\n            # Tính số lượng đúng\n            correct += (predicted == answers).sum().item()\n            total += answers.size(0)\n\n    test_loss /= len(test_loader)\n    test_acc = correct / total\n\n    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n\n    return test_loss, test_acc, predictions\n","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.138982Z","iopub.status.idle":"2025-03-23T13:01:39.139378Z","shell.execute_reply":"2025-03-23T13:01:39.139209Z"},"papermill":{"duration":0.036384,"end_time":"2025-03-22T20:04:09.940973","exception":false,"start_time":"2025-03-22T20:04:09.904589","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e82b6c8f","cell_type":"markdown","source":"# Modeling","metadata":{"papermill":{"duration":0.025694,"end_time":"2025-03-22T20:04:09.993760","exception":false,"start_time":"2025-03-22T20:04:09.968066","status":"completed"},"tags":[]}},{"id":"f02d130a","cell_type":"code","source":"class ImageEncoder(nn.Module):\n    def __init__(self, pretrained=True):\n        super(ImageEncoder, self).__init__()\n        mobilenet = models.mobilenet_v2(pretrained=pretrained)\n        self.feature_extractor = mobilenet.features\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(1280, 256)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        features = self.feature_extractor(x)\n        features = self.pool(features).view(features.size(0), -1)\n        features = self.fc(features)\n        return self.dropout(features)\n\nclass TextEncoder(nn.Module):\n    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=256):\n        super(TextEncoder, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, 256)\n        self.dropout = nn.Dropout(0.2)\n        self.attention = Attention(hidden_dim * 2)\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        attended_lstm_out = self.attention(lstm_out)\n        hidden = self.fc(attended_lstm_out)\n        return self.dropout(hidden)\n\nclass Attention(nn.Module):\n    def __init__(self, input_dim):\n        super(Attention, self).__init__()\n        self.attention_weights = nn.Parameter(torch.randn(input_dim))\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, lstm_out):\n        attention_scores = torch.matmul(lstm_out, self.attention_weights)\n        attention_scores = self.softmax(attention_scores)\n        attention_output = torch.sum(lstm_out * attention_scores.unsqueeze(-1), dim=1)\n        return attention_output\n\nclass VQA(nn.Module):\n    def __init__(self, vocab_size, num_classes):\n        super(VQA, self).__init__()\n        self.image_encoder = ImageEncoder()\n        self.text_encoder = TextEncoder(vocab_size)\n        self.fc_fusion = nn.Linear(256, 256)\n        self.classifier = nn.Linear(256, num_classes)\n\n    def forward(self, question, image):\n        img_features = self.image_encoder(image)\n        text_features = self.text_encoder(question)\n        fused = self.fc_fusion(img_features * text_features)\n        return self.classifier(fused)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.140285Z","iopub.status.idle":"2025-03-23T13:01:39.140662Z","shell.execute_reply":"2025-03-23T13:01:39.140498Z"},"papermill":{"duration":0.039481,"end_time":"2025-03-22T20:04:10.058938","exception":false,"start_time":"2025-03-22T20:04:10.019457","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7488f39d","cell_type":"markdown","source":"## Hyperparameters","metadata":{"papermill":{"duration":0.026273,"end_time":"2025-03-22T20:04:10.111950","exception":false,"start_time":"2025-03-22T20:04:10.085677","status":"completed"},"tags":[]}},{"id":"c2a18cc0","cell_type":"code","source":"model = VQA(\n    vocab_size=question_vocab.size,\n    num_classes=answer_vocab.size\n)\n\nmodel.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.141519Z","iopub.status.idle":"2025-03-23T13:01:39.141899Z","shell.execute_reply":"2025-03-23T13:01:39.141736Z"},"papermill":{"duration":1.152332,"end_time":"2025-03-22T20:04:11.290086","exception":false,"start_time":"2025-03-22T20:04:10.137754","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"0970c9ea","cell_type":"code","source":"epochs = 100\ncriterion = nn.CrossEntropyLoss(ignore_index=question_vocab.PAD_IDX)\noptimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n\nearly_stopping = EarlyStopping(patience=8, verbose=True)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.142648Z","iopub.status.idle":"2025-03-23T13:01:39.143031Z","shell.execute_reply":"2025-03-23T13:01:39.142864Z"},"papermill":{"duration":0.032749,"end_time":"2025-03-22T20:04:11.348665","exception":false,"start_time":"2025-03-22T20:04:11.315916","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"5637b970","cell_type":"markdown","source":"# Training and Evaluation","metadata":{"papermill":{"duration":0.024144,"end_time":"2025-03-22T20:04:11.398347","exception":false,"start_time":"2025-03-22T20:04:11.374203","status":"completed"},"tags":[]}},{"id":"fe0d5984","cell_type":"markdown","source":"## Training","metadata":{"papermill":{"duration":0.027726,"end_time":"2025-03-22T20:04:11.456632","exception":false,"start_time":"2025-03-22T20:04:11.428906","status":"completed"},"tags":[]}},{"id":"e582b242","cell_type":"code","source":"history = train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, early_stopping)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.143763Z","iopub.status.idle":"2025-03-23T13:01:39.144163Z","shell.execute_reply":"2025-03-23T13:01:39.143975Z"},"papermill":{"duration":2241.842097,"end_time":"2025-03-22T20:41:33.325965","exception":false,"start_time":"2025-03-22T20:04:11.483868","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"37dc6dea","cell_type":"markdown","source":"## Testing","metadata":{"papermill":{"duration":0.025898,"end_time":"2025-03-22T20:41:33.377944","exception":false,"start_time":"2025-03-22T20:41:33.352046","status":"completed"},"tags":[]}},{"id":"41c08c6b","cell_type":"code","source":"model.load_state_dict(torch.load(early_stopping.path))\ntest_loss, test_acc, predictions = test(model, test_loader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.145090Z","iopub.status.idle":"2025-03-23T13:01:39.145483Z","shell.execute_reply":"2025-03-23T13:01:39.145323Z"},"papermill":{"duration":24.340582,"end_time":"2025-03-22T20:41:57.745680","exception":false,"start_time":"2025-03-22T20:41:33.405098","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"76d3ef1f","cell_type":"code","source":"def plot_training_history(history, title=\"Training History\"):\n    epochs = range(1, len(history[\"train_loss\"]) + 1)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n    fig.suptitle(title)\n    \n    # Vẽ Train Loss và Eval Loss\n    axes[0].plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n    axes[0].plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n    axes[0].set_xlabel(\"Epochs\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].set_title(\"Training and Validation Loss\")\n    axes[0].legend()\n    axes[0].grid(True)\n    \n    # Vẽ Train Accuracy và Eval Accuracy\n    axes[1].plot(epochs, history[\"train_acc\"], label=\"Train Accuracy\")\n    axes[1].plot(epochs, history[\"val_acc\"], label=\"Val Accuracy\")\n    axes[1].set_xlabel(\"Epochs\")\n    axes[1].set_ylabel(\"Accuracy\")\n    axes[1].set_title(\"Training and Validation Accuracy\")\n    axes[1].legend()\n    axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.146269Z","iopub.status.idle":"2025-03-23T13:01:39.146640Z","shell.execute_reply":"2025-03-23T13:01:39.146476Z"},"papermill":{"duration":0.033976,"end_time":"2025-03-22T20:41:57.806510","exception":false,"start_time":"2025-03-22T20:41:57.772534","status":"completed"},"tags":[],"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"261ede65","cell_type":"code","source":"plot_training_history(history, title='Vqa early fusion')","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.147466Z","iopub.status.idle":"2025-03-23T13:01:39.147903Z","shell.execute_reply":"2025-03-23T13:01:39.147706Z"},"papermill":{"duration":0.677266,"end_time":"2025-03-22T20:41:58.509069","exception":false,"start_time":"2025-03-22T20:41:57.831803","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e26597cc","cell_type":"code","source":"for i in [random.randint(0, len(test_dataset) - 1) for _ in range(20)]:\n    model.eval()\n    if isinstance(model, torch.nn.DataParallel):\n        model.module.eval()\n    question, image, answer = test_dataset[i]\n    \n    question, image = question.to(device), image.to(device)\n\n    with torch.no_grad():\n        output = model(question.unsqueeze(0), image.unsqueeze(0))  \n        predicted_idx = torch.argmax(output, dim=1).item()  \n\n    question_text = test_dataset.data.iloc[i]['question']\n    answer_text = test_dataset.data.iloc[i]['answer']\n\n    predicted_answer = test_dataset.answer_vocab.idx2word(predicted_idx)\n\n    image_np = image.cpu().permute(1, 2, 0).numpy()  #\n    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n\n    plt.imshow(image_np)\n    plt.axis(\"off\")\n    plt.show()\n\n    print(f\"Question: {question_text}\")\n    print(f\"GT Answer: {answer_text}\")\n    print(f\"Predicted Answer: {predicted_answer}\")\n    print(\"-\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-23T13:01:39.148809Z","iopub.status.idle":"2025-03-23T13:01:39.149232Z","shell.execute_reply":"2025-03-23T13:01:39.149044Z"},"papermill":{"duration":1.470318,"end_time":"2025-03-22T20:42:00.009676","exception":false,"start_time":"2025-03-22T20:41:58.539358","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}