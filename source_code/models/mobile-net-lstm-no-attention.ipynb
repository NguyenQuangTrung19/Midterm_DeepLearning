{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11130228,"sourceType":"datasetVersion","datasetId":6941621}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\nimport timm\n\nfrom sklearn.model_selection import train_test_split\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud\n\nimport os\nimport time\nimport warnings\nimport random\nimport string\nfrom collections import Counter\nfrom PIL import Image\n\n\nsns.set_context(\"paper\")\nsns.set_style(\"whitegrid\")\n\nwarnings.filterwarnings('ignore')\nnltk.download('punkt')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:22.922882Z","iopub.execute_input":"2025-03-23T12:51:22.923237Z","iopub.status.idle":"2025-03-23T12:51:33.225420Z","shell.execute_reply.started":"2025-03-23T12:51:22.923211Z","shell.execute_reply":"2025-03-23T12:51:33.224707Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.226458Z","iopub.execute_input":"2025-03-23T12:51:33.226799Z","iopub.status.idle":"2025-03-23T12:51:33.310433Z","shell.execute_reply.started":"2025-03-23T12:51:33.226779Z","shell.execute_reply":"2025-03-23T12:51:33.309690Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Data preparing","metadata":{}},{"cell_type":"code","source":"ROOT = '/kaggle/input/food-vqa/VN20-500_v3'\n# ROOT = '/kaggle/input/hand-image-vqa'\n\n\ntrain_df = pd.read_csv(f'{ROOT}/annotations/train.csv')\nval_df = pd.read_csv(f'{ROOT}/annotations/validation.csv')\ntest_df = pd.read_csv(f'{ROOT}/annotations/test.csv')\n\n\ndata =  pd.concat([train_df, val_df, test_df], ignore_index=True)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.312192Z","iopub.execute_input":"2025-03-23T12:51:33.312572Z","iopub.status.idle":"2025-03-23T12:51:33.504206Z","shell.execute_reply.started":"2025-03-23T12:51:33.312466Z","shell.execute_reply":"2025-03-23T12:51:33.503458Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                         question    answer question_type answer_type  \\\n0               m√≥n n√†y l√† m√≥n g√¨  b√°nh b√®o   recognition        text   \n1   ƒë√¢y c√≥ ph·∫£i l√† b√°nh b√®o kh√¥ng        c√≥        yes/no     boolean   \n2  m√†u ch·ªß ƒë·∫°o c·ªßa b√°nh b√®o l√† g√¨     tr·∫Øng         color        text   \n3              b√°nh b√®o c√≥ m√†u g√¨     tr·∫Øng         color        text   \n4     b√°nh b√®o c√≥ n∆∞·ªõc ch·∫•m kh√¥ng        c√≥        yes/no     boolean   \n\n             image_path  \n0  train/Banh_Beo/1.jpg  \n1  train/Banh_Beo/1.jpg  \n2  train/Banh_Beo/1.jpg  \n3  train/Banh_Beo/1.jpg  \n4  train/Banh_Beo/1.jpg  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_type</th>\n      <th>answer_type</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>m√≥n n√†y l√† m√≥n g√¨</td>\n      <td>b√°nh b√®o</td>\n      <td>recognition</td>\n      <td>text</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ƒë√¢y c√≥ ph·∫£i l√† b√°nh b√®o kh√¥ng</td>\n      <td>c√≥</td>\n      <td>yes/no</td>\n      <td>boolean</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>m√†u ch·ªß ƒë·∫°o c·ªßa b√°nh b√®o l√† g√¨</td>\n      <td>tr·∫Øng</td>\n      <td>color</td>\n      <td>text</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b√°nh b√®o c√≥ m√†u g√¨</td>\n      <td>tr·∫Øng</td>\n      <td>color</td>\n      <td>text</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b√°nh b√®o c√≥ n∆∞·ªõc ch·∫•m kh√¥ng</td>\n      <td>c√≥</td>\n      <td>yes/no</td>\n      <td>boolean</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def clean_text(text):\n    text = text.replace('?', '').replace(',', '').lower().split(' ')\n    return '_'.join(text)\n    \nclasses = {\n    'b√°nh b√®o': 'b√°nh_b√®o',\n    'b√°nh cƒÉn': 'b√°nh_cƒÉn',\n    'b√°nh gi√≤': 'b√°nh_gi√≤',\n    'b√°nh m√¨': 'b√°nh_m√¨',\n    'b√°nh tr√°ng n∆∞·ªõng': 'b√°nh_tr√°ng_n∆∞·ªõng',\n    'b√°nh x√®o': 'b√°nh_x√®o',\n    'b·∫Øp x√†o': 'b·∫Øp_x√†o',\n    'b√∫n b√≤': 'b√∫n_b√≤',\n    'b√∫n ch·∫£': 'b√∫n_ch·∫£',\n    'b√∫n ƒë·∫≠u': 'b√∫n_ƒë·∫≠u',\n    'b√∫n m·∫Øm': 'b√∫n_m·∫Øm',\n    'b√∫n th·ªãt n∆∞·ªõng': 'b√∫n_th·ªãt_n∆∞·ªõng',\n    'cao l·∫ßu': 'cao_l·∫ßu',\n    'ch√°o l√≤ng': 'ch√°o_l√≤ng',\n    'c∆°m t·∫•m': 'c∆°m_t·∫•m',\n    'g·ªèi cu·ªën': 'g·ªèi_cu·ªën',\n    'h·ªß ti·∫øu': 'h·ªß_ti·∫øu',\n    'm√¨ qu·∫£ng': 'm√¨_qu·∫£ng',\n    'ph√° l·∫•u': 'ph√°_l·∫•u',\n    'ph·ªü': 'ph·ªü',\n    'ch·ªß ƒë·∫°o': 'ch·ªß_ƒë·∫°o',\n    'n∆∞·ªõc ch·∫•m': 'n∆∞·ªõc_ch·∫•m',\n    'm√†u s·∫Øc': 'm√†u_s·∫Øc',\n    \n    }\nprint(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}, Test samples: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.505460Z","iopub.execute_input":"2025-03-23T12:51:33.505739Z","iopub.status.idle":"2025-03-23T12:51:33.511292Z","shell.execute_reply.started":"2025-03-23T12:51:33.505712Z","shell.execute_reply":"2025-03-23T12:51:33.510353Z"}},"outputs":[{"name":"stdout","text":"Train samples: 41613, Val samples: 5518, Test samples: 10530\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"data['answer'] = data.answer.apply(clean_text)\ntrain_df['answer'] = train_df.answer.apply(clean_text)\ntest_df['answer'] = test_df.answer.apply(clean_text)\nval_df['answer'] = val_df.answer.apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.512297Z","iopub.execute_input":"2025-03-23T12:51:33.512502Z","iopub.status.idle":"2025-03-23T12:51:33.600085Z","shell.execute_reply.started":"2025-03-23T12:51:33.512484Z","shell.execute_reply":"2025-03-23T12:51:33.599468Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.600804Z","iopub.execute_input":"2025-03-23T12:51:33.601101Z","iopub.status.idle":"2025-03-23T12:51:33.609085Z","shell.execute_reply.started":"2025-03-23T12:51:33.601074Z","shell.execute_reply":"2025-03-23T12:51:33.608392Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                         question    answer question_type answer_type  \\\n0               m√≥n n√†y l√† m√≥n g√¨  b√°nh_b√®o   recognition        text   \n1   ƒë√¢y c√≥ ph·∫£i l√† b√°nh b√®o kh√¥ng        c√≥        yes/no     boolean   \n2  m√†u ch·ªß ƒë·∫°o c·ªßa b√°nh b√®o l√† g√¨     tr·∫Øng         color        text   \n3              b√°nh b√®o c√≥ m√†u g√¨     tr·∫Øng         color        text   \n4     b√°nh b√®o c√≥ n∆∞·ªõc ch·∫•m kh√¥ng        c√≥        yes/no     boolean   \n\n             image_path  \n0  train/Banh_Beo/1.jpg  \n1  train/Banh_Beo/1.jpg  \n2  train/Banh_Beo/1.jpg  \n3  train/Banh_Beo/1.jpg  \n4  train/Banh_Beo/1.jpg  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_type</th>\n      <th>answer_type</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>m√≥n n√†y l√† m√≥n g√¨</td>\n      <td>b√°nh_b√®o</td>\n      <td>recognition</td>\n      <td>text</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ƒë√¢y c√≥ ph·∫£i l√† b√°nh b√®o kh√¥ng</td>\n      <td>c√≥</td>\n      <td>yes/no</td>\n      <td>boolean</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>m√†u ch·ªß ƒë·∫°o c·ªßa b√°nh b√®o l√† g√¨</td>\n      <td>tr·∫Øng</td>\n      <td>color</td>\n      <td>text</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b√°nh b√®o c√≥ m√†u g√¨</td>\n      <td>tr·∫Øng</td>\n      <td>color</td>\n      <td>text</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b√°nh b√®o c√≥ n∆∞·ªõc ch·∫•m kh√¥ng</td>\n      <td>c√≥</td>\n      <td>yes/no</td>\n      <td>boolean</td>\n      <td>train/Banh_Beo/1.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.609785Z","iopub.execute_input":"2025-03-23T12:51:33.610063Z","iopub.status.idle":"2025-03-23T12:51:33.658206Z","shell.execute_reply.started":"2025-03-23T12:51:33.610043Z","shell.execute_reply":"2025-03-23T12:51:33.657679Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57661 entries, 0 to 57660\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   question       57661 non-null  object\n 1   answer         57661 non-null  object\n 2   question_type  57661 non-null  object\n 3   answer_type    57661 non-null  object\n 4   image_path     57661 non-null  object\ndtypes: object(5)\nmemory usage: 2.2+ MB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.659216Z","iopub.execute_input":"2025-03-23T12:51:33.659540Z","iopub.status.idle":"2025-03-23T12:51:33.721488Z","shell.execute_reply.started":"2025-03-23T12:51:33.659505Z","shell.execute_reply":"2025-03-23T12:51:33.720862Z"},"jupyter":{"source_hidden":true}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                              question answer question_type answer_type  \\\ncount                            57661  57661         57661       57661   \nunique                            3135     27             3           2   \ntop     m√†u s·∫Øc ch√≠nh c·ªßa m√≥n ƒÉn l√† g√¨     c√≥        yes/no        text   \nfreq                              2130  21860         23837       32797   \n\n                   image_path  \ncount                   57661  \nunique                   9720  \ntop     train/Banh_Beo/10.jpg  \nfreq                       14  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_type</th>\n      <th>answer_type</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>57661</td>\n      <td>57661</td>\n      <td>57661</td>\n      <td>57661</td>\n      <td>57661</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3135</td>\n      <td>27</td>\n      <td>3</td>\n      <td>2</td>\n      <td>9720</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>m√†u s·∫Øc ch√≠nh c·ªßa m√≥n ƒÉn l√† g√¨</td>\n      <td>c√≥</td>\n      <td>yes/no</td>\n      <td>text</td>\n      <td>train/Banh_Beo/10.jpg</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>2130</td>\n      <td>21860</td>\n      <td>23837</td>\n      <td>32797</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"questions = data.question\nanswers = data.answer\n\n\nlen(questions), len(answers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.723670Z","iopub.execute_input":"2025-03-23T12:51:33.723904Z","iopub.status.idle":"2025-03-23T12:51:33.728717Z","shell.execute_reply.started":"2025-03-23T12:51:33.723884Z","shell.execute_reply":"2025-03-23T12:51:33.727891Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(57661, 57661)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class Vocab():\n    def __init__(self, texts, pad_token='<pad>', unk_token='<unk>', pad_idx=0, unk_idx=1):\n        self.PAD_TOKEN = pad_token\n        self.UNK_TOKEN = unk_token\n        self.PAD_IDX = pad_idx\n        self.UNK_IDX = unk_idx\n        \n        self.vocab = self._build_vocab(texts)\n        self.vocab2idx = {word: idx for idx, word in enumerate(self.vocab)}\n        self.size = len(self.vocab)\n\n    def word2idx(self, vocab):\n        if vocab in self.vocab2idx:\n            return self.vocab2idx[vocab]\n        else:\n            return self.vocab2idx[self.UNK_TOKEN]\n\n    def idx2word(self, idx):\n        return self.vocab[idx]\n\n    def _build_vocab(self, texts, min_freq=5):\n        counter = Counter()\n        for text in texts:\n            tokens = word_tokenize(text.lower())\n            counter.update(tokens)\n    \n        vocab = [self.PAD_TOKEN, self.UNK_TOKEN]  \n        for word, freq in counter.items():\n            if freq >= min_freq: \n                vocab.append(word)\n                \n        return vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.730183Z","iopub.execute_input":"2025-03-23T12:51:33.730456Z","iopub.status.idle":"2025-03-23T12:51:33.742501Z","shell.execute_reply.started":"2025-03-23T12:51:33.730425Z","shell.execute_reply":"2025-03-23T12:51:33.741708Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, data, q_vocab, a_vocab, transform=None, max_len=30, image_folder=f'{ROOT}/images'):\n        self.data = data\n        self.question_vocab = q_vocab\n        self.answer_vocab = a_vocab\n        # self.question_vocab = Vocab(self.data.question)\n        # self.answer_vocab = Vocab(self.data.answer)\n        self.transform = transform \n        \n        self.image_folder = image_folder\n        self.MAX_QUESTION_LEN = data.question.apply(lambda x: len(x.split(' '))).max()\n        self.MAX_ANSWER_LEN = data.answer.apply(lambda x: len(x.split(' '))).max()\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        \n        question = row['question']\n        answer = row['answer']\n        image_id = row['image_path']\n\n        question_tokens = word_tokenize(question)\n        question_indices = [self.question_vocab.word2idx(token) for token in question_tokens]\n        question_indices = question_indices[:self.MAX_QUESTION_LEN]  # C·∫Øt n·∫øu qu√° d√†i\n        question_indices += [self.question_vocab.PAD_IDX] * (self.MAX_QUESTION_LEN - len(question_indices))  # Padding n·∫øu qu√° ng·∫Øn\n\n        # answer_token = word_tokenize(answer)  \n        answer_idx = self.answer_vocab.word2idx(answer)\n\n        image_path = os.path.join(self.image_folder, image_id)\n        image = Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n\n        return torch.tensor(question_indices, dtype=torch.long), image, torch.tensor(answer_idx, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.743248Z","iopub.execute_input":"2025-03-23T12:51:33.743489Z","iopub.status.idle":"2025-03-23T12:51:33.760099Z","shell.execute_reply.started":"2025-03-23T12:51:33.743470Z","shell.execute_reply":"2025-03-23T12:51:33.759280Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"question_vocab = Vocab(questions)\nanswer_vocab = Vocab(answers)\n\nanswer_vocab.vocab\nquestion_vocab.vocab\nlen(question_vocab.vocab), len(answer_vocab.vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:33.760961Z","iopub.execute_input":"2025-03-23T12:51:33.761245Z","iopub.status.idle":"2025-03-23T12:51:40.939022Z","shell.execute_reply.started":"2025-03-23T12:51:33.761214Z","shell.execute_reply":"2025-03-23T12:51:40.938255Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(127, 29)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def show_images_with_questions(data, num_samples=5, root=f'{ROOT}/images'):\n    unique_images = data[\"image_path\"].unique()[:num_samples]  # L·∫•y N ·∫£nh ƒë·∫ßu ti√™n\n    \n    for img_path in unique_images:\n        # L·∫•y danh s√°ch c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi li√™n quan ƒë·∫øn ·∫£nh\n        related_questions = data[data[\"image_path\"] == img_path][[\"question\", \"answer\"]]\n        \n        # Load v√† hi·ªÉn th·ªã ·∫£nh\n        img = Image.open(f'{root}/{img_path}')\n        plt.figure(figsize=(5, 5))\n        plt.imshow(img)\n        plt.axis(\"off\")\n\n        # In c√°c c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi\n        print(f\"üì∑ **H√¨nh ·∫£nh:** {img_path}\")\n        for _, row in related_questions.iterrows():\n            print(f\"‚ùì {row['question']}\")\n            print(f\"‚úÖ {row['answer']}\")\n            print(\"-\" * 50)\n\n        plt.show()\n\n# Hi·ªÉn th·ªã ·∫£nh v·ªõi c√¢u h·ªèi\n# show_images_with_questions(train_df, num_samples=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:40.939684Z","iopub.execute_input":"2025-03-23T12:51:40.939908Z","iopub.status.idle":"2025-03-23T12:51:40.945261Z","shell.execute_reply.started":"2025-03-23T12:51:40.939889Z","shell.execute_reply":"2025-03-23T12:51:40.944381Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def collate_fn(batch, PAD_IDX=0):\n    questions, images, answers = zip(*batch) \n    \n    questions = [torch.tensor(q) for q in questions]\n    padded_questions = pad_sequence(questions, batch_first=True, padding_value=PAD_IDX)\n\n    answer = [torch.tensor(a) for a in answers]\n    # answers = [torch.tensor(a) for a in answers]\n    # padded_answers = pad_sequence(answers, batch_first=True, padding_value=PAD_IDX)\n    \n    images = torch.stack(images)  \n    answer = torch.tensor(answer) \n\n    return padded_questions, images, answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:40.946093Z","iopub.execute_input":"2025-03-23T12:51:40.946393Z","iopub.status.idle":"2025-03-23T12:51:40.975976Z","shell.execute_reply.started":"2025-03-23T12:51:40.946362Z","shell.execute_reply":"2025-03-23T12:51:40.975198Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:40.976783Z","iopub.execute_input":"2025-03-23T12:51:40.977032Z","iopub.status.idle":"2025-03-23T12:51:40.992524Z","shell.execute_reply.started":"2025-03-23T12:51:40.977012Z","shell.execute_reply":"2025-03-23T12:51:40.991785Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_dataset = VQADataset(train_df, question_vocab, answer_vocab, transform=transform)\nval_dataset = VQADataset(val_df, question_vocab, answer_vocab, transform=transform)\ntest_dataset = VQADataset(test_df, question_vocab, answer_vocab, transform=transform)\n\nlen(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:40.993208Z","iopub.execute_input":"2025-03-23T12:51:40.993423Z","iopub.status.idle":"2025-03-23T12:51:41.072266Z","shell.execute_reply.started":"2025-03-23T12:51:40.993405Z","shell.execute_reply":"2025-03-23T12:51:41.071620Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"41613"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, drop_last=True, num_workers=10)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True, num_workers=10)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, drop_last=True, num_workers=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.073007Z","iopub.execute_input":"2025-03-23T12:51:41.073201Z","iopub.status.idle":"2025-03-23T12:51:41.077584Z","shell.execute_reply.started":"2025-03-23T12:51:41.073184Z","shell.execute_reply":"2025-03-23T12:51:41.076882Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_val_loss = None\n        self.early_stop = False\n        self.val_loss_min = np.inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n        # Check if validation loss is nan\n        if np.isnan(val_loss):\n            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n            return\n\n        if self.best_val_loss is None:\n            self.best_val_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n        elif val_loss < self.best_val_loss - self.delta:\n            # Significant improvement detected\n            self.best_val_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0  # Reset counter since improvement occurred\n        else:\n            # No significant improvement\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decreases.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.078339Z","iopub.execute_input":"2025-03-23T12:51:41.078610Z","iopub.status.idle":"2025-03-23T12:51:41.092920Z","shell.execute_reply.started":"2025-03-23T12:51:41.078591Z","shell.execute_reply":"2025-03-23T12:51:41.092188Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def update_history(history, train_loss, val_loss, train_acc, val_acc):\n    history[\"train_loss\"].append(train_loss)\n    history[\"val_loss\"].append(val_loss)\n    history[\"train_acc\"].append(train_acc)\n    history[\"val_acc\"].append(val_acc)\n\ndef log_training(epoch, epochs, train_loss, train_acc, val_loss, val_acc, early_stopping, start_time):\n    end_time = time.time()\n    print(f\"{'-' * 50}\")\n    print(f\"Epoch: {epoch + 1}/{epochs}:\")\n    print(f\"\\tTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"\\tVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    print(f\"\\tEarly Stopping Counter: {early_stopping.counter}, Time: {end_time - start_time:.2f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.093600Z","iopub.execute_input":"2025-03-23T12:51:41.093819Z","iopub.status.idle":"2025-03-23T12:51:41.110102Z","shell.execute_reply.started":"2025-03-23T12:51:41.093790Z","shell.execute_reply":"2025-03-23T12:51:41.109416Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def validate(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n\n    with torch.no_grad():\n        for questions, images, answers in val_loader:\n            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n\n            output = model(questions, images)  # [batch, num_answer]\n\n            loss = criterion(output, answers)\n            val_loss += loss.item()\n\n            # T√≠nh accuracy\n            predicted = torch.argmax(output, dim=-1)  # [batch]\n            correct_val += (predicted == answers).sum().item()\n            total_val += answers.size(0)\n\n    val_loss /= len(val_loader)\n    val_acc = correct_val / total_val\n\n    return val_loss, val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.110762Z","iopub.execute_input":"2025-03-23T12:51:41.110957Z","iopub.status.idle":"2025-03-23T12:51:41.122969Z","shell.execute_reply.started":"2025-03-23T12:51:41.110941Z","shell.execute_reply":"2025-03-23T12:51:41.122219Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, early_stopping):\n    history = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"train_acc\": [],\n        \"val_acc\": []\n    }\n\n    print('Start training...')\n    for epoch in range(epochs):\n        start_time = time.time()\n        \n        model.train()\n        train_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        for questions, images, answers in train_loader:\n            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n\n            optimizer.zero_grad()\n            output = model(questions, images)  # [batch_size, num_answer]\n            \n\n            loss = criterion(output, answers)  # [batch, num_answer] v√† [batch]\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n\n            # T√≠nh accuracy\n            predicted = torch.argmax(output, dim=-1)  # [batch]\n            correct_train += (predicted == answers).sum().item()\n            total_train += answers.size(0)\n\n        train_loss /= len(train_loader)\n        train_acc = correct_train / total_train\n\n        # Validation\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n\n        update_history(history, train_loss, val_loss, train_acc, val_acc)\n        # scheduler.step(val_loss)\n\n        early_stopping(val_loss, model)\n        if early_stopping.early_stop:\n            print(\"Early stopping triggered\")\n            break\n    \n        log_training(epoch, epochs, train_loss, train_acc, val_loss, val_acc, early_stopping, start_time)\n\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.123672Z","iopub.execute_input":"2025-03-23T12:51:41.123943Z","iopub.status.idle":"2025-03-23T12:51:41.139981Z","shell.execute_reply.started":"2025-03-23T12:51:41.123910Z","shell.execute_reply":"2025-03-23T12:51:41.139170Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def test(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n    predictions = []\n\n    with torch.no_grad():\n        for questions, images, answers in test_loader:\n            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n\n            output = model(questions, images)  # [batch, num_answer]\n\n            # T√≠nh loss\n            loss = criterion(output, answers)\n            test_loss += loss.item()\n\n            # L·∫•y nh√£n d·ª± ƒëo√°n\n            predicted = torch.argmax(output, dim=-1)  # [batch]\n            predictions.append(predicted.cpu().numpy())  # Chuy·ªÉn sang numpy ƒë·ªÉ ph√¢n t√≠ch\n\n            # T√≠nh s·ªë l∆∞·ª£ng ƒë√∫ng\n            correct += (predicted == answers).sum().item()\n            total += answers.size(0)\n\n    test_loss /= len(test_loader)\n    test_acc = correct / total\n\n    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n\n    return test_loss, test_acc, predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.140758Z","iopub.execute_input":"2025-03-23T12:51:41.140987Z","iopub.status.idle":"2025-03-23T12:51:41.156532Z","shell.execute_reply.started":"2025-03-23T12:51:41.140957Z","shell.execute_reply":"2025-03-23T12:51:41.155849Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"class ImageEncoder(nn.Module):\n    def __init__(self, pretrained=True):\n        super(ImageEncoder, self).__init__()\n        mobilenet = models.mobilenet_v2(pretrained=pretrained)\n        self.feature_extractor = mobilenet.features\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(1280, 256)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        features = self.feature_extractor(x)\n        features = self.pool(features).view(features.size(0), -1)\n        features = self.fc(features)\n        return self.dropout(features)\n\nclass TextEncoder(nn.Module):\n    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=256):\n        super(TextEncoder, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, 256)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        hidden = lstm_out[:, -1, :]\n        hidden = self.fc(hidden)\n        return self.dropout(hidden)\n\nclass VQA(nn.Module):\n    def __init__(self, vocab_size, num_classes):\n        super(VQA, self).__init__()\n\n        self.image_encoder = ImageEncoder()\n        self.text_encoder = TextEncoder(vocab_size)\n\n        self.fc_fusion = nn.Linear(256, 256)\n        self.classifier = nn.Linear(256, num_classes)\n\n    def forward(self, question, image):\n        img_features = self.image_encoder(image)\n        text_features = self.text_encoder(question)\n\n        fused = self.fc_fusion(img_features * text_features)\n\n        return self.classifier(fused)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.157260Z","iopub.execute_input":"2025-03-23T12:51:41.157530Z","iopub.status.idle":"2025-03-23T12:51:41.175481Z","shell.execute_reply.started":"2025-03-23T12:51:41.157502Z","shell.execute_reply":"2025-03-23T12:51:41.174609Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"model = VQA(\n    vocab_size=question_vocab.size,\n    num_classes=answer_vocab.size\n)\n\nmodel.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.176175Z","iopub.execute_input":"2025-03-23T12:51:41.176424Z","iopub.status.idle":"2025-03-23T12:51:41.804659Z","shell.execute_reply.started":"2025-03-23T12:51:41.176406Z","shell.execute_reply":"2025-03-23T12:51:41.803767Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.6M/13.6M [00:00<00:00, 143MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"epochs = 100\ncriterion = nn.CrossEntropyLoss(ignore_index=question_vocab.PAD_IDX)\noptimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n\n# early_stopping = EarlyStopping() \nearly_stopping = EarlyStopping(patience=8, verbose=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.805632Z","iopub.execute_input":"2025-03-23T12:51:41.805985Z","iopub.status.idle":"2025-03-23T12:51:41.811219Z","shell.execute_reply.started":"2025-03-23T12:51:41.805951Z","shell.execute_reply":"2025-03-23T12:51:41.810507Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Training and Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"history = train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, early_stopping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:51:41.811963Z","iopub.execute_input":"2025-03-23T12:51:41.812244Z","execution_failed":"2025-03-23T12:59:52.153Z"}},"outputs":[{"name":"stdout","text":"Start training...\nValidation loss decreased (inf --> 0.745821).  Saving model ...\n--------------------------------------------------\nEpoch: 1/100:\n\tTrain Loss: 0.9610, Train Acc: 0.6765\n\tVal Loss: 0.7221, Val Acc: 0.7458\n\tEarly Stopping Counter: 0, Time: 193.49s\nEarlyStopping counter: 1 out of 12\n--------------------------------------------------\nEpoch: 2/100:\n\tTrain Loss: 0.6454, Train Acc: 0.7759\n\tVal Loss: 0.6192, Val Acc: 0.7793\n\tEarly Stopping Counter: 1, Time: 188.73s\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(early_stopping.path))\ntest_loss, test_acc, predictions = test(model, test_loader, criterion, device)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-23T12:59:52.154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history, title=\"Training History\"):\n    epochs = range(1, len(history[\"train_loss\"]) + 1)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n    fig.suptitle(title)\n    \n    # V·∫Ω Train Loss v√† Eval Loss\n    axes[0].plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n    axes[0].plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n    axes[0].set_xlabel(\"Epochs\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].set_title(\"Training and Validation Loss\")\n    axes[0].legend()\n    axes[0].grid(True)\n    \n    # V·∫Ω Train Accuracy v√† Eval Accuracy\n    axes[1].plot(epochs, history[\"train_acc\"], label=\"Train Accuracy\")\n    axes[1].plot(epochs, history[\"val_acc\"], label=\"Val Accuracy\")\n    axes[1].set_xlabel(\"Epochs\")\n    axes[1].set_ylabel(\"Accuracy\")\n    axes[1].set_title(\"Training and Validation Accuracy\")\n    axes[1].legend()\n    axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-23T12:59:52.154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_history(history, title='Vqa early fusion')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-23T12:59:52.154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in [random.randint(0, len(test_dataset) - 1) for _ in range(20)]:\n    model.eval()\n    if isinstance(model, torch.nn.DataParallel):\n        model.module.eval()\n    question, image, answer = test_dataset[i]\n    \n    question, image = question.to(device), image.to(device)\n\n    with torch.no_grad():\n        output = model(question.unsqueeze(0), image.unsqueeze(0))  \n        predicted_idx = torch.argmax(output, dim=1).item()  \n\n    question_text = test_dataset.data.iloc[i]['question']\n    answer_text = test_dataset.data.iloc[i]['answer']\n\n    predicted_answer = test_dataset.answer_vocab.idx2word(predicted_idx)\n\n    image_np = image.cpu().permute(1, 2, 0).numpy()  #\n    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n\n    plt.imshow(image_np)\n    plt.axis(\"off\")\n    plt.show()\n\n    print(f\"Question: {question_text}\")\n    print(f\"GT Answer: {answer_text}\")\n    print(f\"Predicted Answer: {predicted_answer}\")\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-23T12:59:52.154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}